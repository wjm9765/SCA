import os
import sys
import warnings
import numpy as np
import torch
from datasets import Dataset
from swift.llm import sft_main, TrainArguments, register_dataset, DatasetMeta
from sca_data.dataset_utils import easy_load

# -------------------------------------------------------------------------
# [1] í™˜ê²½ ì„¤ì •
# -------------------------------------------------------------------------
#os.environ["MODELSCOPE_CACHE"] = "/workspace/modelscope_cache"
os.environ["VLLM_LOGGING_LEVEL"] = "ERROR"
os.environ["TRANSFORMERS_NO_ADVISORY_WARNINGS"] = "1"
#os.environ["CUDA_LAUNCH_BLOCKING"] = "1"
#os.environ["TORCH_UES_CUDA_DSA"] = '1'

os.makedirs("/workspace/tmp", exist_ok=True)
os.makedirs("/workspace/modelscope_cache", exist_ok=True)
warnings.filterwarnings("ignore")

#MODEL_ID = "Qwen/Qwen3-Omni-30B-A3B-Instruct"
MODEL_ID = "/workspace/models/huihui_uncensored"
CUSTOM_TEMPLATE = "qwen3-omni-sca"
DATASET_NAME = "sca_audio_final"

def quiet_print(*args):
    if int(os.environ.get("LOCAL_RANK", 0)) == 0:
        print(*args, flush=True)

# -------------------------------------------------------------------------
# [2] í¬ë§· ë³€í™˜ í•¨ìˆ˜ (ê¸°ì¡´ easy_load ì¶œë ¥ -> Qwen í¬ë§·)
# -------------------------------------------------------------------------
def convert_batch_to_qwen_format(batch):
    """
    easy_loadê°€ ë§Œë“  'í‘œì¤€ Chat í¬ë§·(ë¦¬ìŠ¤íŠ¸)'ì„ 
    Qwenì´ ì¢‹ì•„í•˜ëŠ” '<audio> íƒœê·¸ ë¬¸ìì—´' í¬ë§·ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    (ë°°ì¹˜ ë‹¨ìœ„ ì²˜ë¦¬)
    """
    ret_messages = []
    ret_audios = []

    # batch["messages"]ëŠ” ë¦¬ìŠ¤íŠ¸ì˜ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. (Batch Sizeë§Œí¼)
    for conversation in batch["messages"]:
        new_conv = []
        new_conv_audios = []

        for msg in conversation:
            role = msg["role"]
            content = msg["content"]
            
            # contentê°€ ë¦¬ìŠ¤íŠ¸(ë©€í‹°ëª¨ë‹¬)ì¸ ê²½ìš° ë³€í™˜ ìˆ˜í–‰
            if isinstance(content, list):
                new_text = ""
                for item in content:
                    if item["type"] == "text":
                        new_text += item["text"] + "\n"
                    elif item["type"] == "audio":
                        # 1. ì˜¤ë””ì˜¤ íŒŒí˜• ì¶”ì¶œ
                        # (easy_loadê°€ ì´ë¯¸ ë¡œë“œí•´ë‘” np.arrayë¥¼ ê°€ì ¸ì˜´)
                        wave = item.get("audio_waveform")
                        if isinstance(wave, np.ndarray) and wave.dtype != np.float32:
                            wave = wave.astype(np.float32)
                        new_conv_audios.append(wave)
                        
                        # 2. <audio> íƒœê·¸ ì‚½ì…
                        new_text += "<audio>"
                
                new_conv.append({"role": role, "content": new_text.strip()})
            else:
                # í…ìŠ¤íŠ¸ë§Œ ìˆëŠ” ê²½ìš° ê·¸ëŒ€ë¡œ ìœ ì§€
                new_conv.append({"role": role, "content": content})
        
        ret_messages.append(new_conv)
        ret_audios.append(new_conv_audios)

    return {"messages": ret_messages, "audios": ret_audios}

# -------------------------------------------------------------------------
# [3] ë¡œë” í•¨ìˆ˜ (ê¸°ì¡´ Transform ë‚šì•„ì±„ê¸° ê¸°ìˆ  ì ìš©)
# -------------------------------------------------------------------------
# dataset_metaë¥¼ ë°›ì•„ì£¼ê±°ë‚˜, *argsë¡œ ëª¨ë“  ì¶”ê°€ ì¸ìë¥¼ ë¬´ì‹œí•´ì•¼ í•¨
def my_hijack_loader(dataset_id, dataset_meta=None, **kwargs):
    quiet_print("ğŸš€ Loading Dataset via easy_load (Lazy Mode)...")
    
    # 1. easy_load í˜¸ì¶œ (ì´ ì‹œì ì—ëŠ” ì˜¤ë””ì˜¤ê°€ ë¡œë“œë˜ì§€ ì•ŠìŒ)
    ds = easy_load(format="chat")
    # --------------------------------------------------------
    # [ğŸ”¥ í•µì‹¬ ìˆ˜ì •] 20ê°œë§Œ ìë¥´ê¸° (ë°ì´í„° ë¡œë“œ ì—†ì´ ì¸ë±ìŠ¤ë§Œ ìë¦„)
    # --------------------------------------------------------
    TEST_COUNT = 20
    if len(ds) > TEST_COUNT:
        quiet_print(f"âœ‚ï¸ [TEST MODE] Slicing dataset: {len(ds)} -> {TEST_COUNT} samples.")
        # .select()ëŠ” ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì— ì˜¬ë¦¬ì§€ ì•Šê³  Viewë§Œ ë§Œë“­ë‹ˆë‹¤. (Lazy ìœ ì§€)
        ds = ds.select(range(TEST_COUNT))
    else:
        quiet_print(f"â„¹ï¸ Dataset is smaller than {TEST_COUNT}, using full dataset.")
    # --------------------------------------------------------
    # 2. [í•µì‹¬ ê¸°ìˆ ] ê¸°ì¡´ Transform í•¨ìˆ˜ ì¶”ì¶œ
    # easy_loadê°€ ì„¤ì •í•´ë‘” 'ì˜¤ë””ì˜¤ ë¡œë”© ë¡œì§'ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    # (HuggingFace Dataset ë‚´ë¶€ ë³€ìˆ˜ _format_kwargs ì ‘ê·¼)
    old_transform = ds._format_kwargs.get('transform')
    
    if old_transform is None:
        quiet_print("âš ï¸ Warning: No existing transform found. Making a generic one.")
        old_transform = lambda x: x

    # 3. ìƒˆë¡œìš´ Transform ì •ì˜ (ê¸°ì¡´ ë¡œì§ + ë³€í™˜ ë¡œì§ ì—°ê²°)
    def new_lazy_transform(batch):
        # (1) ë¨¼ì € easy_loadì˜ ê¸°ì¡´ ë¡œì§ì„ ì‹¤í–‰í•˜ì—¬ ì˜¤ë””ì˜¤ë¥¼ ë¡œë“œí•¨ (Lazy)
        intermediate_batch = old_transform(batch)
        
        # (2) ë¡œë“œëœ ë°ì´í„°ì˜ í¬ë§·ì„ Qwenìš©ìœ¼ë¡œ ë³€í™˜í•¨
        final_batch = convert_batch_to_qwen_format(intermediate_batch)
        
        return final_batch

    # 4. ë°ì´í„°ì…‹ì— ìƒˆë¡œìš´ Transform ì ìš©
    ds.set_transform(new_lazy_transform)
    
    quiet_print(f"âœ… Transform Hijacked & Applied. Total samples: {len(ds)}")
    
    # í…ŒìŠ¤íŠ¸ìš© ìŠ¬ë¼ì´ì‹± (í•„ìš” ì‹œ)
    # if len(ds) > 10:
    #    ds = ds.select(range(10))
        
    return ds

# -------------------------------------------------------------------------
# [4] ë°ì´í„°ì…‹ ë“±ë¡
# -------------------------------------------------------------------------
register_dataset(
    DatasetMeta(
        dataset_name=DATASET_NAME,
        load_function=my_hijack_loader,
    )
)

# # -------------------------------------------------------------------------
# # [5] í•™ìŠµ ì„¤ì • (ìš”ì²­í•˜ì‹  ëŒ€ë¡œ OOM ë°©ì§€ ì˜µì…˜ ì œê±°)
# # -------------------------------------------------------------------------
# train_args = TrainArguments(
#     model_kwargs={"device_map": "auto"},
#     model=MODEL_ID,
#     model_type=None,

#     custom_register_path="./template.py",
#     template=CUSTOM_TEMPLATE,

#     dataset=[DATASET_NAME],

#     train_type="lora",
#     # [Target Modules] Thinkerë§Œ íƒ€ê²ŸíŒ… (ì„±ê³µí–ˆë˜ ì„¤ì •)
#     target_modules=r"^thinker\.model\.layers\.\d+\..*(q|k|v|o)_proj$",

#     lora_rank=16,
#     lora_alpha=32,
#     lora_dropout=0.05,

#     freeze_vit=True,
#     freeze_aligner=True,

#     bf16=True,
#     num_train_epochs=1,
#     per_device_train_batch_size=1,
#     gradient_accumulation_steps=4,
#     learning_rate=1e-4,
#     max_length=2048,
#     output_dir="./qwen3_omni_sca_result",

#     logging_steps=1,
#     save_steps=10,
#     save_total_limit=2,

#     # [Lazy ì„¤ì •]
#     lazy_tokenize=True,
#     dataset_num_proc=1,      
#     dataloader_num_workers=0, # ë©”ì¸ í”„ë¡œì„¸ìŠ¤ì—ì„œ ë¡œë“œ (ì˜¤ë¥˜ ë°©ì§€)
    
#     load_from_cache_file=False, 
# )
# ... (ì•ë¶€ë¶„ ë™ì¼) ...
train_args = TrainArguments(
    # --- ê¸°ë³¸ ì„¤ì • ---
    model=MODEL_ID,
    model_type="qwen3_omni",
    #model_type=None,
    custom_register_path="./template.py",
    template="qwen3-omni-sca",
    
    # ë°ì´í„°ì…‹ ì§ì ‘ ê²½ë¡œ ì§€ì •
    dataset=[DATASET_NAME],
    # --- í•™ìŠµ ë°©ì‹ ---
    train_type="lora",
    
    # [Target Modules] ë¬¸ì œì˜ MLP ë ˆì´ì–´ í¬í•¨ (4bit ë¡œë“œ ì‹œ ë©”ëª¨ë¦¬ ë¬¸ì œ ì—†ìŒ)
    target_modules=r"^thinker\.model\.layers\.\d+\..*(q|k|v|o)_proj$",

    # --- LoRA ì„¤ì • ---
    lora_rank=16,
    lora_alpha=32,
    lora_dropout=0.05,

    # --- ë©€í‹°ëª¨ë‹¬ ë™ê²° ---
    freeze_vit=True,
    freeze_aligner=True,

    # --- â˜…â˜…â˜… [í•µì‹¬ ìˆ˜ì •] Quantization Arguments (ê³µì‹ ë¬¸ì„œ ê¸°ì¤€) â˜…â˜…â˜… ---
    # 1. ì–‘ìí™” ë°©ì‹ ì§€ì • (í•„ìˆ˜)
    quant_method="bnb", 
    
    # 2. ë¹„íŠ¸ ìˆ˜ (quantization_bit -> quant_bits)
    quant_bits=4, 
    
    # 3. ì—°ì‚° íƒ€ì… (bnb_4bit_comp_dtype -> bnb_4bit_compute_dtype)
    bnb_4bit_compute_dtype="bfloat16", 
    
    # 4. ì–‘ìí™” íƒ€ì…
    bnb_4bit_quant_type="nf4",
    
    # 5. ì´ì¤‘ ì–‘ìí™” ì‚¬ìš© (ë©”ëª¨ë¦¬ ì¶”ê°€ ì ˆì•½)
    bnb_4bit_use_double_quant=True,

    # --- í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„° ---
    bf16=True,  # A40ì€ bf16 ì§€ì›í•¨
    num_train_epochs=1,
    per_device_train_batch_size=1,
    
    # Gradient Checkpointingì€ 4bit í•™ìŠµ ì‹œ í•„ìˆ˜ (ë©”ëª¨ë¦¬ ì ˆì•½)
    gradient_checkpointing=True, 
    gradient_accumulation_steps=4,
    learning_rate=1e-4,
    max_length=2048,

    # --- ì €ì¥ ë° ë¡œê¹… ---
    output_dir="/workspace/qwen3_omni_sca_result",
    logging_steps=1,
    save_steps=10,
    save_total_limit=2,

    # --- ë°ì´í„° ì²˜ë¦¬ ---
    lazy_tokenize=True,
    dataset_num_proc=1,      
    dataloader_num_workers=0,
    load_from_cache_file=False,

    #ddp í•™ìŠµ ìœ„í•œ ì„¤ì • 

# # NPROC_PER_NODE=2 : GPU 2ê°œë¥¼ ì“°ê² ë‹¤ëŠ” ëœ»
# torchrun --nproc_per_node=2 --master_port=29500 train_fly_ver.py
    #optim="paged_adamw_8bit",
    ddp_find_unused_parameters=True,
    
    # --- í˜¸í™˜ì„± ë° ì•ˆì „ ì¥ì¹˜ ---
    # check_dataset_strategy="none",  # í•„ìš” ì‹œ ì£¼ì„ í•´ì œ (ì´ì „ ì˜¤ë¥˜ ê´€ë ¨)
    # model_kwargs={"pad_token_id": 151645} # í•„ìš” ì‹œ ì£¼ì„ í•´ì œ (ì´ì „ ì˜¤ë¥˜ ê´€ë ¨)
)

# ... (ë’·ë¶€ë¶„ ë™ì¼) ...
# -------------------------------------------------------------------------
# [6] í•™ìŠµ ì‹œì‘
# -------------------------------------------------------------------------
if __name__ == "__main__":
    quiet_print("ğŸ Starting training (Integrated Lazy Mode)...")
    sft_main(train_args)